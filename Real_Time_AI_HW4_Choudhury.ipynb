{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Real Time AI - HW4 Choudhury Github",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d34e670746e40878e0df2cb3b5e167b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5f14e5b870a148839c6a44df43374f24",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae6231936acb48faa5ae16078e37e20e",
              "IPY_MODEL_08eec9935a4347d8a5570bb1bed369b4"
            ]
          }
        },
        "5f14e5b870a148839c6a44df43374f24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae6231936acb48faa5ae16078e37e20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_071fcce7a7fb4039b3212b80cf8401f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47e3936ca37f4585aa5dd3e4cc9ab1e4"
          }
        },
        "08eec9935a4347d8a5570bb1bed369b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc359d15f9cf421cb4c1a83504f2ecc0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:09&lt;00:00, 17483831.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_750bee47cda94e94bbe2d3afce749996"
          }
        },
        "071fcce7a7fb4039b3212b80cf8401f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47e3936ca37f4585aa5dd3e4cc9ab1e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc359d15f9cf421cb4c1a83504f2ecc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "750bee47cda94e94bbe2d3afce749996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EChoudhury/RealTimeAI/blob/main/Real_Time_AI_HW4_Choudhury.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv8-AQoyNsnq",
        "outputId": "dbb6bb95-4c8c-487a-8c9f-738b53496329"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f852599c8f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDDChEIlNsn4"
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "6d34e670746e40878e0df2cb3b5e167b",
            "5f14e5b870a148839c6a44df43374f24",
            "ae6231936acb48faa5ae16078e37e20e",
            "08eec9935a4347d8a5570bb1bed369b4",
            "071fcce7a7fb4039b3212b80cf8401f6",
            "47e3936ca37f4585aa5dd3e4cc9ab1e4",
            "fc359d15f9cf421cb4c1a83504f2ecc0",
            "750bee47cda94e94bbe2d3afce749996"
          ]
        },
        "id": "jmr-jNHANsn6",
        "outputId": "8687a5a0-e1de-4519-92c4-8a2c496c8fe5"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch7/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch7/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d34e670746e40878e0df2cb3b5e167b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ../data-unversioned/p1ch7/cifar-10-python.tar.gz to ../data-unversioned/p1ch7/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r8Yr96xNsn7"
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ3-nlgqNsn9"
      },
      "source": [
        "label_map = {6: 0, 7: 1, 8: 2, 9: 3}\n",
        "class_names = ['frog', 'horse', 'ship','truck']\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10 \n",
        "          if label in [6, 7, 8, 9]]\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [6, 7, 8, 9]]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oGFmD8HY9b1"
      },
      "source": [
        "**Question 1 Part 1:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amulNGXoNsoR"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rQ09uMbNsoU",
        "outputId": "de7ad2a6-c00f-469b-c668-75ef1e4b4099"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 4),\n",
        "            nn.LogSoftmax(dim=1))\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "\n",
        "t = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "elapsed = time.time() - t\n",
        "print(\"Elapsed Training Time: %s\" % elapsed)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.745326\n",
            "Epoch: 1, Loss: 0.646128\n",
            "Epoch: 2, Loss: 0.797681\n",
            "Epoch: 3, Loss: 0.797029\n",
            "Epoch: 4, Loss: 0.667015\n",
            "Epoch: 5, Loss: 0.583316\n",
            "Epoch: 6, Loss: 0.913675\n",
            "Epoch: 7, Loss: 0.500480\n",
            "Epoch: 8, Loss: 0.572505\n",
            "Epoch: 9, Loss: 0.684698\n",
            "Epoch: 10, Loss: 0.590175\n",
            "Epoch: 11, Loss: 0.713271\n",
            "Epoch: 12, Loss: 0.457858\n",
            "Epoch: 13, Loss: 0.451838\n",
            "Epoch: 14, Loss: 0.422193\n",
            "Epoch: 15, Loss: 0.513691\n",
            "Epoch: 16, Loss: 0.670527\n",
            "Epoch: 17, Loss: 0.325947\n",
            "Epoch: 18, Loss: 0.453996\n",
            "Epoch: 19, Loss: 0.557100\n",
            "Epoch: 20, Loss: 0.377720\n",
            "Epoch: 21, Loss: 0.351241\n",
            "Epoch: 22, Loss: 0.300203\n",
            "Epoch: 23, Loss: 0.329142\n",
            "Epoch: 24, Loss: 0.278762\n",
            "Epoch: 25, Loss: 0.240725\n",
            "Epoch: 26, Loss: 0.371935\n",
            "Epoch: 27, Loss: 0.171413\n",
            "Epoch: 28, Loss: 0.122777\n",
            "Epoch: 29, Loss: 0.242501\n",
            "Epoch: 30, Loss: 0.196924\n",
            "Epoch: 31, Loss: 0.106221\n",
            "Epoch: 32, Loss: 0.167923\n",
            "Epoch: 33, Loss: 0.076605\n",
            "Epoch: 34, Loss: 0.130320\n",
            "Epoch: 35, Loss: 0.127546\n",
            "Epoch: 36, Loss: 0.139069\n",
            "Epoch: 37, Loss: 0.173204\n",
            "Epoch: 38, Loss: 0.098087\n",
            "Epoch: 39, Loss: 0.104630\n",
            "Epoch: 40, Loss: 0.171795\n",
            "Epoch: 41, Loss: 0.083699\n",
            "Epoch: 42, Loss: 0.067718\n",
            "Epoch: 43, Loss: 0.038186\n",
            "Epoch: 44, Loss: 0.076516\n",
            "Epoch: 45, Loss: 0.066348\n",
            "Epoch: 46, Loss: 0.112702\n",
            "Epoch: 47, Loss: 0.093993\n",
            "Epoch: 48, Loss: 0.064829\n",
            "Epoch: 49, Loss: 0.042878\n",
            "Epoch: 50, Loss: 0.083492\n",
            "Epoch: 51, Loss: 0.064377\n",
            "Epoch: 52, Loss: 0.113614\n",
            "Epoch: 53, Loss: 0.109474\n",
            "Epoch: 54, Loss: 0.058128\n",
            "Epoch: 55, Loss: 0.022197\n",
            "Epoch: 56, Loss: 0.069295\n",
            "Epoch: 57, Loss: 0.037508\n",
            "Epoch: 58, Loss: 0.025592\n",
            "Epoch: 59, Loss: 0.018273\n",
            "Epoch: 60, Loss: 0.035010\n",
            "Epoch: 61, Loss: 0.016273\n",
            "Epoch: 62, Loss: 0.032881\n",
            "Epoch: 63, Loss: 0.051055\n",
            "Epoch: 64, Loss: 0.030540\n",
            "Epoch: 65, Loss: 0.022560\n",
            "Epoch: 66, Loss: 0.038194\n",
            "Epoch: 67, Loss: 0.036133\n",
            "Epoch: 68, Loss: 0.027442\n",
            "Epoch: 69, Loss: 0.015030\n",
            "Epoch: 70, Loss: 0.023017\n",
            "Epoch: 71, Loss: 0.023689\n",
            "Epoch: 72, Loss: 0.020754\n",
            "Epoch: 73, Loss: 0.012624\n",
            "Epoch: 74, Loss: 0.024573\n",
            "Epoch: 75, Loss: 0.026391\n",
            "Epoch: 76, Loss: 0.026680\n",
            "Epoch: 77, Loss: 0.023896\n",
            "Epoch: 78, Loss: 0.020157\n",
            "Epoch: 79, Loss: 0.030742\n",
            "Epoch: 80, Loss: 0.026650\n",
            "Epoch: 81, Loss: 0.013864\n",
            "Epoch: 82, Loss: 0.012385\n",
            "Epoch: 83, Loss: 0.010432\n",
            "Epoch: 84, Loss: 0.010260\n",
            "Epoch: 85, Loss: 0.014430\n",
            "Epoch: 86, Loss: 0.012687\n",
            "Epoch: 87, Loss: 0.010398\n",
            "Epoch: 88, Loss: 0.015221\n",
            "Epoch: 89, Loss: 0.011710\n",
            "Epoch: 90, Loss: 0.013729\n",
            "Epoch: 91, Loss: 0.012183\n",
            "Epoch: 92, Loss: 0.010537\n",
            "Epoch: 93, Loss: 0.009835\n",
            "Epoch: 94, Loss: 0.016884\n",
            "Epoch: 95, Loss: 0.007684\n",
            "Epoch: 96, Loss: 0.019139\n",
            "Epoch: 97, Loss: 0.011535\n",
            "Epoch: 98, Loss: 0.012063\n",
            "Epoch: 99, Loss: 0.051556\n",
            "Epoch: 100, Loss: 0.009063\n",
            "Epoch: 101, Loss: 0.014064\n",
            "Epoch: 102, Loss: 0.007180\n",
            "Epoch: 103, Loss: 0.013147\n",
            "Epoch: 104, Loss: 0.008137\n",
            "Epoch: 105, Loss: 0.011761\n",
            "Epoch: 106, Loss: 0.009348\n",
            "Epoch: 107, Loss: 0.013191\n",
            "Epoch: 108, Loss: 0.008609\n",
            "Epoch: 109, Loss: 0.010587\n",
            "Epoch: 110, Loss: 0.019434\n",
            "Epoch: 111, Loss: 0.014501\n",
            "Epoch: 112, Loss: 0.009024\n",
            "Epoch: 113, Loss: 0.006623\n",
            "Epoch: 114, Loss: 0.009394\n",
            "Epoch: 115, Loss: 0.012434\n",
            "Epoch: 116, Loss: 0.009425\n",
            "Epoch: 117, Loss: 0.005723\n",
            "Epoch: 118, Loss: 0.007306\n",
            "Epoch: 119, Loss: 0.012212\n",
            "Epoch: 120, Loss: 0.008513\n",
            "Epoch: 121, Loss: 0.009391\n",
            "Epoch: 122, Loss: 0.005982\n",
            "Epoch: 123, Loss: 0.007222\n",
            "Epoch: 124, Loss: 0.016035\n",
            "Epoch: 125, Loss: 0.006827\n",
            "Epoch: 126, Loss: 0.006042\n",
            "Epoch: 127, Loss: 0.004501\n",
            "Epoch: 128, Loss: 0.009183\n",
            "Epoch: 129, Loss: 0.008580\n",
            "Epoch: 130, Loss: 0.007872\n",
            "Epoch: 131, Loss: 0.007476\n",
            "Epoch: 132, Loss: 0.007418\n",
            "Epoch: 133, Loss: 0.007770\n",
            "Epoch: 134, Loss: 0.010097\n",
            "Epoch: 135, Loss: 0.008185\n",
            "Epoch: 136, Loss: 0.007580\n",
            "Epoch: 137, Loss: 0.007082\n",
            "Epoch: 138, Loss: 0.011108\n",
            "Epoch: 139, Loss: 0.007571\n",
            "Epoch: 140, Loss: 0.007281\n",
            "Epoch: 141, Loss: 0.007130\n",
            "Epoch: 142, Loss: 0.007788\n",
            "Epoch: 143, Loss: 0.007128\n",
            "Epoch: 144, Loss: 0.004938\n",
            "Epoch: 145, Loss: 0.007405\n",
            "Epoch: 146, Loss: 0.004450\n",
            "Epoch: 147, Loss: 0.006144\n",
            "Epoch: 148, Loss: 0.004300\n",
            "Epoch: 149, Loss: 0.005404\n",
            "Epoch: 150, Loss: 0.005417\n",
            "Epoch: 151, Loss: 0.005004\n",
            "Epoch: 152, Loss: 0.005829\n",
            "Epoch: 153, Loss: 0.006768\n",
            "Epoch: 154, Loss: 0.006653\n",
            "Epoch: 155, Loss: 0.004811\n",
            "Epoch: 156, Loss: 0.005572\n",
            "Epoch: 157, Loss: 0.004142\n",
            "Epoch: 158, Loss: 0.004304\n",
            "Epoch: 159, Loss: 0.004342\n",
            "Epoch: 160, Loss: 0.005187\n",
            "Epoch: 161, Loss: 0.006562\n",
            "Epoch: 162, Loss: 0.005223\n",
            "Epoch: 163, Loss: 0.007021\n",
            "Epoch: 164, Loss: 0.003506\n",
            "Epoch: 165, Loss: 0.005406\n",
            "Epoch: 166, Loss: 0.005753\n",
            "Epoch: 167, Loss: 0.004938\n",
            "Epoch: 168, Loss: 0.005410\n",
            "Epoch: 169, Loss: 0.003616\n",
            "Epoch: 170, Loss: 0.003201\n",
            "Epoch: 171, Loss: 0.005007\n",
            "Epoch: 172, Loss: 0.004252\n",
            "Epoch: 173, Loss: 0.002959\n",
            "Epoch: 174, Loss: 0.005649\n",
            "Epoch: 175, Loss: 0.004660\n",
            "Epoch: 176, Loss: 0.002589\n",
            "Epoch: 177, Loss: 0.004637\n",
            "Epoch: 178, Loss: 0.005632\n",
            "Epoch: 179, Loss: 0.005673\n",
            "Epoch: 180, Loss: 0.004769\n",
            "Epoch: 181, Loss: 0.002536\n",
            "Epoch: 182, Loss: 0.005473\n",
            "Epoch: 183, Loss: 0.004426\n",
            "Epoch: 184, Loss: 0.006090\n",
            "Epoch: 185, Loss: 0.002592\n",
            "Epoch: 186, Loss: 0.004454\n",
            "Epoch: 187, Loss: 0.003782\n",
            "Epoch: 188, Loss: 0.004063\n",
            "Epoch: 189, Loss: 0.003290\n",
            "Epoch: 190, Loss: 0.002372\n",
            "Epoch: 191, Loss: 0.004282\n",
            "Epoch: 192, Loss: 0.004809\n",
            "Epoch: 193, Loss: 0.002828\n",
            "Epoch: 194, Loss: 0.005009\n",
            "Epoch: 195, Loss: 0.005347\n",
            "Epoch: 196, Loss: 0.004429\n",
            "Epoch: 197, Loss: 0.003321\n",
            "Epoch: 198, Loss: 0.002365\n",
            "Epoch: 199, Loss: 0.007843\n",
            "Elapsed Training Time: 595.0582294464111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRB8AOBcNsoU"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEFJkrNANsoV",
        "outputId": "7ec4137f-2c4d-479b-db2d-b1b846deecbc"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.774000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfoPlmtNY2Os"
      },
      "source": [
        "**Question 1, Part 2:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtX516B9NsoV"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 2),\n",
        "            nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7fvEPJINsoW"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 2))\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGpaDtrANsoW",
        "outputId": "834d87fa-884c-4c96-ceb5-5ed7210e8e0a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 4))\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "\n",
        "t = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "elapsed = time.time() - t\n",
        "print(\"Elapsed Training Time: %s\" % elapsed)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.901608\n",
            "Epoch: 1, Loss: 0.802176\n",
            "Epoch: 2, Loss: 0.482365\n",
            "Epoch: 3, Loss: 0.843536\n",
            "Epoch: 4, Loss: 0.826616\n",
            "Epoch: 5, Loss: 0.605048\n",
            "Epoch: 6, Loss: 0.696433\n",
            "Epoch: 7, Loss: 0.674695\n",
            "Epoch: 8, Loss: 0.652445\n",
            "Epoch: 9, Loss: 0.729730\n",
            "Epoch: 10, Loss: 0.479166\n",
            "Epoch: 11, Loss: 0.650773\n",
            "Epoch: 12, Loss: 0.618325\n",
            "Epoch: 13, Loss: 0.218682\n",
            "Epoch: 14, Loss: 0.519471\n",
            "Epoch: 15, Loss: 0.368111\n",
            "Epoch: 16, Loss: 0.435241\n",
            "Epoch: 17, Loss: 0.497027\n",
            "Epoch: 18, Loss: 0.312156\n",
            "Epoch: 19, Loss: 0.454031\n",
            "Epoch: 20, Loss: 0.315858\n",
            "Epoch: 21, Loss: 0.103988\n",
            "Epoch: 22, Loss: 0.109139\n",
            "Epoch: 23, Loss: 0.187654\n",
            "Epoch: 24, Loss: 0.694715\n",
            "Epoch: 25, Loss: 0.092136\n",
            "Epoch: 26, Loss: 0.086972\n",
            "Epoch: 27, Loss: 0.172950\n",
            "Epoch: 28, Loss: 0.075441\n",
            "Epoch: 29, Loss: 0.100773\n",
            "Epoch: 30, Loss: 0.142153\n",
            "Epoch: 31, Loss: 0.037859\n",
            "Epoch: 32, Loss: 0.055102\n",
            "Epoch: 33, Loss: 0.042593\n",
            "Epoch: 34, Loss: 0.059024\n",
            "Epoch: 35, Loss: 0.028703\n",
            "Epoch: 36, Loss: 0.025711\n",
            "Epoch: 37, Loss: 0.024649\n",
            "Epoch: 38, Loss: 0.004080\n",
            "Epoch: 39, Loss: 0.017557\n",
            "Epoch: 40, Loss: 0.004878\n",
            "Epoch: 41, Loss: 0.008883\n",
            "Epoch: 42, Loss: 0.006869\n",
            "Epoch: 43, Loss: 0.003319\n",
            "Epoch: 44, Loss: 0.003744\n",
            "Epoch: 45, Loss: 0.005558\n",
            "Epoch: 46, Loss: 0.002160\n",
            "Epoch: 47, Loss: 0.005722\n",
            "Epoch: 48, Loss: 0.006491\n",
            "Epoch: 49, Loss: 0.002717\n",
            "Epoch: 50, Loss: 0.005620\n",
            "Epoch: 51, Loss: 0.002750\n",
            "Epoch: 52, Loss: 0.002659\n",
            "Epoch: 53, Loss: 0.001913\n",
            "Epoch: 54, Loss: 0.002988\n",
            "Epoch: 55, Loss: 0.002002\n",
            "Epoch: 56, Loss: 0.001055\n",
            "Epoch: 57, Loss: 0.004934\n",
            "Epoch: 58, Loss: 0.001637\n",
            "Epoch: 59, Loss: 0.001869\n",
            "Epoch: 60, Loss: 0.000811\n",
            "Epoch: 61, Loss: 0.001968\n",
            "Epoch: 62, Loss: 0.001658\n",
            "Epoch: 63, Loss: 0.001452\n",
            "Epoch: 64, Loss: 0.001195\n",
            "Epoch: 65, Loss: 0.001379\n",
            "Epoch: 66, Loss: 0.002118\n",
            "Epoch: 67, Loss: 0.001391\n",
            "Epoch: 68, Loss: 0.001313\n",
            "Epoch: 69, Loss: 0.000987\n",
            "Epoch: 70, Loss: 0.001007\n",
            "Epoch: 71, Loss: 0.001013\n",
            "Epoch: 72, Loss: 0.002284\n",
            "Epoch: 73, Loss: 0.000826\n",
            "Epoch: 74, Loss: 0.001430\n",
            "Epoch: 75, Loss: 0.000858\n",
            "Epoch: 76, Loss: 0.000688\n",
            "Epoch: 77, Loss: 0.000718\n",
            "Epoch: 78, Loss: 0.001097\n",
            "Epoch: 79, Loss: 0.000965\n",
            "Epoch: 80, Loss: 0.001040\n",
            "Epoch: 81, Loss: 0.000687\n",
            "Epoch: 82, Loss: 0.000894\n",
            "Epoch: 83, Loss: 0.000565\n",
            "Epoch: 84, Loss: 0.000374\n",
            "Epoch: 85, Loss: 0.000961\n",
            "Epoch: 86, Loss: 0.001472\n",
            "Epoch: 87, Loss: 0.000978\n",
            "Epoch: 88, Loss: 0.000549\n",
            "Epoch: 89, Loss: 0.001041\n",
            "Epoch: 90, Loss: 0.000704\n",
            "Epoch: 91, Loss: 0.000867\n",
            "Epoch: 92, Loss: 0.000473\n",
            "Epoch: 93, Loss: 0.001159\n",
            "Epoch: 94, Loss: 0.000395\n",
            "Epoch: 95, Loss: 0.000553\n",
            "Epoch: 96, Loss: 0.000651\n",
            "Epoch: 97, Loss: 0.000518\n",
            "Epoch: 98, Loss: 0.000789\n",
            "Epoch: 99, Loss: 0.000678\n",
            "Epoch: 100, Loss: 0.000472\n",
            "Epoch: 101, Loss: 0.000843\n",
            "Epoch: 102, Loss: 0.000522\n",
            "Epoch: 103, Loss: 0.000619\n",
            "Epoch: 104, Loss: 0.000596\n",
            "Epoch: 105, Loss: 0.000756\n",
            "Epoch: 106, Loss: 0.000533\n",
            "Epoch: 107, Loss: 0.000653\n",
            "Epoch: 108, Loss: 0.000465\n",
            "Epoch: 109, Loss: 0.000749\n",
            "Epoch: 110, Loss: 0.000547\n",
            "Epoch: 111, Loss: 0.000426\n",
            "Epoch: 112, Loss: 0.000689\n",
            "Epoch: 113, Loss: 0.000354\n",
            "Epoch: 114, Loss: 0.000860\n",
            "Epoch: 115, Loss: 0.000208\n",
            "Epoch: 116, Loss: 0.000601\n",
            "Epoch: 117, Loss: 0.000961\n",
            "Epoch: 118, Loss: 0.000580\n",
            "Epoch: 119, Loss: 0.000570\n",
            "Epoch: 120, Loss: 0.000487\n",
            "Epoch: 121, Loss: 0.000373\n",
            "Epoch: 122, Loss: 0.000313\n",
            "Epoch: 123, Loss: 0.000258\n",
            "Epoch: 124, Loss: 0.000280\n",
            "Epoch: 125, Loss: 0.000490\n",
            "Epoch: 126, Loss: 0.000328\n",
            "Epoch: 127, Loss: 0.000247\n",
            "Epoch: 128, Loss: 0.000352\n",
            "Epoch: 129, Loss: 0.000479\n",
            "Epoch: 130, Loss: 0.000211\n",
            "Epoch: 131, Loss: 0.000353\n",
            "Epoch: 132, Loss: 0.000321\n",
            "Epoch: 133, Loss: 0.000620\n",
            "Epoch: 134, Loss: 0.000501\n",
            "Epoch: 135, Loss: 0.000228\n",
            "Epoch: 136, Loss: 0.000378\n",
            "Epoch: 137, Loss: 0.000631\n",
            "Epoch: 138, Loss: 0.000367\n",
            "Epoch: 139, Loss: 0.000112\n",
            "Epoch: 140, Loss: 0.000336\n",
            "Epoch: 141, Loss: 0.000679\n",
            "Epoch: 142, Loss: 0.000302\n",
            "Epoch: 143, Loss: 0.000479\n",
            "Epoch: 144, Loss: 0.000311\n",
            "Epoch: 145, Loss: 0.000230\n",
            "Epoch: 146, Loss: 0.000260\n",
            "Epoch: 147, Loss: 0.000264\n",
            "Epoch: 148, Loss: 0.000248\n",
            "Epoch: 149, Loss: 0.000426\n",
            "Epoch: 150, Loss: 0.000191\n",
            "Epoch: 151, Loss: 0.000282\n",
            "Epoch: 152, Loss: 0.000290\n",
            "Epoch: 153, Loss: 0.000330\n",
            "Epoch: 154, Loss: 0.000366\n",
            "Epoch: 155, Loss: 0.000626\n",
            "Epoch: 156, Loss: 0.000311\n",
            "Epoch: 157, Loss: 0.000163\n",
            "Epoch: 158, Loss: 0.000311\n",
            "Epoch: 159, Loss: 0.000169\n",
            "Epoch: 160, Loss: 0.000195\n",
            "Epoch: 161, Loss: 0.000671\n",
            "Epoch: 162, Loss: 0.000308\n",
            "Epoch: 163, Loss: 0.000340\n",
            "Epoch: 164, Loss: 0.000718\n",
            "Epoch: 165, Loss: 0.000512\n",
            "Epoch: 166, Loss: 0.000177\n",
            "Epoch: 167, Loss: 0.000307\n",
            "Epoch: 168, Loss: 0.000323\n",
            "Epoch: 169, Loss: 0.000332\n",
            "Epoch: 170, Loss: 0.000561\n",
            "Epoch: 171, Loss: 0.000176\n",
            "Epoch: 172, Loss: 0.000323\n",
            "Epoch: 173, Loss: 0.000337\n",
            "Epoch: 174, Loss: 0.000268\n",
            "Epoch: 175, Loss: 0.000388\n",
            "Epoch: 176, Loss: 0.000397\n",
            "Epoch: 177, Loss: 0.000305\n",
            "Epoch: 178, Loss: 0.000263\n",
            "Epoch: 179, Loss: 0.000109\n",
            "Epoch: 180, Loss: 0.000315\n",
            "Epoch: 181, Loss: 0.000139\n",
            "Epoch: 182, Loss: 0.000184\n",
            "Epoch: 183, Loss: 0.000307\n",
            "Epoch: 184, Loss: 0.000183\n",
            "Epoch: 185, Loss: 0.000225\n",
            "Epoch: 186, Loss: 0.000235\n",
            "Epoch: 187, Loss: 0.000323\n",
            "Epoch: 188, Loss: 0.000100\n",
            "Epoch: 189, Loss: 0.000351\n",
            "Epoch: 190, Loss: 0.000249\n",
            "Epoch: 191, Loss: 0.000319\n",
            "Epoch: 192, Loss: 0.000302\n",
            "Epoch: 193, Loss: 0.000303\n",
            "Epoch: 194, Loss: 0.000200\n",
            "Epoch: 195, Loss: 0.000244\n",
            "Epoch: 196, Loss: 0.000150\n",
            "Epoch: 197, Loss: 0.000148\n",
            "Epoch: 198, Loss: 0.000212\n",
            "Epoch: 199, Loss: 0.000184\n",
            "Elapsed Training Time: 1546.8125874996185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mp6HiuJNsoW",
        "outputId": "917fa1c9-f1b0-41b2-b2af-8708376b2f12"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVBBqaffNsoX",
        "outputId": "ded8aae0-6021-4ef0-fbc9-6ba640befa8a"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.762000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_OTz_1hNsoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d585e9d2-7f66-485b-a77b-faaf340dd1bf"
      },
      "source": [
        "sum([p.numel() for p in nn.Linear(3072, 1024).parameters()])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3146752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zce-2WxvNsoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57c5206-9bac-48c4-b626-3c95d290931b"
      },
      "source": [
        "linear = nn.Linear(3072, 1024)\n",
        "\n",
        "linear.weight.shape, linear.bias.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1024, 3072]), torch.Size([1024]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SUQUyccNsoa"
      },
      "source": [
        "conv = nn.Conv2d(3, 16, kernel_size=3)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV_ZYKheNsob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16a942a-36e5-4aa4-bc4a-9c6b759f953c"
      },
      "source": [
        "conv.weight.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCyYPYivNsob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3046cb-f847-4a21-9f10-e7a5ff520932"
      },
      "source": [
        "conv.bias.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdHGmxMQNsoc"
      },
      "source": [
        "img, _ = cifar2[0]\n",
        "\n",
        "output = conv(img.unsqueeze(0))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWk7PJmXNsoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba0b2c4-bf78-422b-a40b-2e4a2ba55e49"
      },
      "source": [
        "img.unsqueeze(0).shape, output.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndIZ0n-qNsod",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "f6637855-6e84-4b2e-8cf4-ae72d21b141e"
      },
      "source": [
        "plt.imshow(img.permute(1, 2, 0), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM_7W8_dNsod",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "fea800b5-9d3a-4723-9995-4e539f82c930"
      },
      "source": [
        "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qWjgPv9Nsoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3650d909-a572-4519-adcd-f4de951e1abf"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 30, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgVHaVGLNsoe"
      },
      "source": [
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU3VSesANsoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e07f21-77dd-44a2-a7e8-22a424edb0ac"
      },
      "source": [
        "output = conv(img.unsqueeze(0))\n",
        "\n",
        "output.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cNsPQ8wNsof"
      },
      "source": [
        "with torch.no_grad():\n",
        "    conv.bias.zero_()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cYs2GX_Nsof"
      },
      "source": [
        "with torch.no_grad():\n",
        "    conv.weight.fill_(1.0 / 9.0)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1VJqySmNsog",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "be4f4a7a-cc53-4f25-de02-6516c9f213d9"
      },
      "source": [
        "output = conv(img.unsqueeze(0))\n",
        "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfOB6-2aNsog"
      },
      "source": [
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
        "                                   [-1.0, 0.0, 1.0],\n",
        "                                   [-1.0, 0.0, 1.0]])\n",
        "    conv.bias.zero_()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_ZzvckJNsoh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "44d59bb4-c89e-4772-9790-69a9d7ed1539"
      },
      "source": [
        "output = conv(img.unsqueeze(0))\n",
        "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LQsE4IENsoh"
      },
      "source": [
        "pool = nn.MaxPool2d(2)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXPw24_uNsoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d23e01-6547-4f0c-cb59-367c0e07f158"
      },
      "source": [
        "output = pool(img.unsqueeze(0))\n",
        "\n",
        "output.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 16, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2D7YgRPNsoj"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            # WARNING: something missing here\n",
        "            nn.Linear(512, 32),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(32, 2))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1bXTy8kNsoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2babb7e-3900-4616-d815-5a5a58137c2e"
      },
      "source": [
        "sum([p.numel() for p in model.parameters()])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18090"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzy1Wq8UNsoj"
      },
      "source": [
        "#model(img.unsqueeze(0))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfwndQfaNsoj"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.Tanh()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.act4 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = self.act4(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJInqU5wNsok",
        "outputId": "aa3a0c98-096e-46e6-a79c-f3caf5e7cdeb"
      },
      "source": [
        "model = Net()\n",
        "\n",
        "sum([p.numel() for p in model.parameters()])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18090"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNIlUp8CNsok"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXVYs5qpNsok",
        "outputId": "05ba0ad8-aeef-46d2-a146-d1c1539064fb"
      },
      "source": [
        "model = Net()\n",
        "model(img.unsqueeze(0))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0175, -0.1526]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32s5ZeVlaDRP"
      },
      "source": [
        "**Question 2 Part 1:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi8g2_7uNsok",
        "outputId": "c33e1f2b-4897-4f44-c35a-711d70e032e9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,shuffle=True)\n",
        "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "print(\"Training on %s.\" % device)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 4)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n",
        "model = Net()\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "\n",
        "t = time.time()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "elapsed = time.time() - t\n",
        "print(\"Elapsed Training Time: %s\" % elapsed)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on cuda.\n",
            "Epoch: 0, Loss: 1.098813\n",
            "Epoch: 1, Loss: 0.737105\n",
            "Epoch: 2, Loss: 0.702897\n",
            "Epoch: 3, Loss: 0.532809\n",
            "Epoch: 4, Loss: 0.694577\n",
            "Epoch: 5, Loss: 0.493176\n",
            "Epoch: 6, Loss: 0.797063\n",
            "Epoch: 7, Loss: 0.592678\n",
            "Epoch: 8, Loss: 0.557560\n",
            "Epoch: 9, Loss: 0.312157\n",
            "Epoch: 10, Loss: 0.438442\n",
            "Epoch: 11, Loss: 0.529617\n",
            "Epoch: 12, Loss: 0.421011\n",
            "Epoch: 13, Loss: 0.353759\n",
            "Epoch: 14, Loss: 0.424824\n",
            "Epoch: 15, Loss: 0.496984\n",
            "Epoch: 16, Loss: 0.213986\n",
            "Epoch: 17, Loss: 0.263669\n",
            "Epoch: 18, Loss: 0.224474\n",
            "Epoch: 19, Loss: 0.354286\n",
            "Epoch: 20, Loss: 0.167596\n",
            "Epoch: 21, Loss: 0.386157\n",
            "Epoch: 22, Loss: 0.444350\n",
            "Epoch: 23, Loss: 0.263629\n",
            "Epoch: 24, Loss: 0.311011\n",
            "Epoch: 25, Loss: 0.318216\n",
            "Epoch: 26, Loss: 0.504663\n",
            "Epoch: 27, Loss: 0.352319\n",
            "Epoch: 28, Loss: 0.449613\n",
            "Epoch: 29, Loss: 0.120360\n",
            "Epoch: 30, Loss: 0.255378\n",
            "Epoch: 31, Loss: 0.311483\n",
            "Epoch: 32, Loss: 0.172962\n",
            "Epoch: 33, Loss: 0.215175\n",
            "Epoch: 34, Loss: 0.428238\n",
            "Epoch: 35, Loss: 0.263389\n",
            "Epoch: 36, Loss: 0.177081\n",
            "Epoch: 37, Loss: 0.282921\n",
            "Epoch: 38, Loss: 0.175925\n",
            "Epoch: 39, Loss: 0.110001\n",
            "Epoch: 40, Loss: 0.205092\n",
            "Epoch: 41, Loss: 0.091150\n",
            "Epoch: 42, Loss: 0.095219\n",
            "Epoch: 43, Loss: 0.121420\n",
            "Epoch: 44, Loss: 0.234195\n",
            "Epoch: 45, Loss: 0.055055\n",
            "Epoch: 46, Loss: 0.209116\n",
            "Epoch: 47, Loss: 0.069922\n",
            "Epoch: 48, Loss: 0.361642\n",
            "Epoch: 49, Loss: 0.275820\n",
            "Epoch: 50, Loss: 0.078593\n",
            "Epoch: 51, Loss: 0.090905\n",
            "Epoch: 52, Loss: 0.170742\n",
            "Epoch: 53, Loss: 0.045038\n",
            "Epoch: 54, Loss: 0.165476\n",
            "Epoch: 55, Loss: 0.081537\n",
            "Epoch: 56, Loss: 0.205929\n",
            "Epoch: 57, Loss: 0.108119\n",
            "Epoch: 58, Loss: 0.209380\n",
            "Epoch: 59, Loss: 0.107326\n",
            "Epoch: 60, Loss: 0.150414\n",
            "Epoch: 61, Loss: 0.119924\n",
            "Epoch: 62, Loss: 0.026064\n",
            "Epoch: 63, Loss: 0.056347\n",
            "Epoch: 64, Loss: 0.031147\n",
            "Epoch: 65, Loss: 0.179417\n",
            "Epoch: 66, Loss: 0.127488\n",
            "Epoch: 67, Loss: 0.224187\n",
            "Epoch: 68, Loss: 0.061403\n",
            "Epoch: 69, Loss: 0.107569\n",
            "Epoch: 70, Loss: 0.049323\n",
            "Epoch: 71, Loss: 0.228319\n",
            "Epoch: 72, Loss: 0.106790\n",
            "Epoch: 73, Loss: 0.068665\n",
            "Epoch: 74, Loss: 0.174593\n",
            "Epoch: 75, Loss: 0.025862\n",
            "Epoch: 76, Loss: 0.225282\n",
            "Epoch: 77, Loss: 0.146034\n",
            "Epoch: 78, Loss: 0.036503\n",
            "Epoch: 79, Loss: 0.045389\n",
            "Epoch: 80, Loss: 0.059127\n",
            "Epoch: 81, Loss: 0.014150\n",
            "Epoch: 82, Loss: 0.055036\n",
            "Epoch: 83, Loss: 0.033184\n",
            "Epoch: 84, Loss: 0.058958\n",
            "Epoch: 85, Loss: 0.170312\n",
            "Epoch: 86, Loss: 0.075260\n",
            "Epoch: 87, Loss: 0.072154\n",
            "Epoch: 88, Loss: 0.015818\n",
            "Epoch: 89, Loss: 0.089986\n",
            "Epoch: 90, Loss: 0.094242\n",
            "Epoch: 91, Loss: 0.044602\n",
            "Epoch: 92, Loss: 0.025234\n",
            "Epoch: 93, Loss: 0.053367\n",
            "Epoch: 94, Loss: 0.136007\n",
            "Epoch: 95, Loss: 0.037300\n",
            "Epoch: 96, Loss: 0.031415\n",
            "Epoch: 97, Loss: 0.034391\n",
            "Epoch: 98, Loss: 0.037066\n",
            "Epoch: 99, Loss: 0.026167\n",
            "Epoch: 100, Loss: 0.131312\n",
            "Epoch: 101, Loss: 0.048534\n",
            "Epoch: 102, Loss: 0.052483\n",
            "Epoch: 103, Loss: 0.023694\n",
            "Epoch: 104, Loss: 0.016082\n",
            "Epoch: 105, Loss: 0.024292\n",
            "Epoch: 106, Loss: 0.020814\n",
            "Epoch: 107, Loss: 0.050098\n",
            "Epoch: 108, Loss: 0.027492\n",
            "Epoch: 109, Loss: 0.004746\n",
            "Epoch: 110, Loss: 0.031976\n",
            "Epoch: 111, Loss: 0.013697\n",
            "Epoch: 112, Loss: 0.017531\n",
            "Epoch: 113, Loss: 0.046471\n",
            "Epoch: 114, Loss: 0.028028\n",
            "Epoch: 115, Loss: 0.015686\n",
            "Epoch: 116, Loss: 0.011399\n",
            "Epoch: 117, Loss: 0.023928\n",
            "Epoch: 118, Loss: 0.013676\n",
            "Epoch: 119, Loss: 0.021226\n",
            "Epoch: 120, Loss: 0.033619\n",
            "Epoch: 121, Loss: 0.048019\n",
            "Epoch: 122, Loss: 0.016549\n",
            "Epoch: 123, Loss: 0.038997\n",
            "Epoch: 124, Loss: 0.019663\n",
            "Epoch: 125, Loss: 0.024595\n",
            "Epoch: 126, Loss: 0.019286\n",
            "Epoch: 127, Loss: 0.024796\n",
            "Epoch: 128, Loss: 0.009323\n",
            "Epoch: 129, Loss: 0.026546\n",
            "Epoch: 130, Loss: 0.016134\n",
            "Epoch: 131, Loss: 0.010690\n",
            "Epoch: 132, Loss: 0.032108\n",
            "Epoch: 133, Loss: 0.021144\n",
            "Epoch: 134, Loss: 0.009173\n",
            "Epoch: 135, Loss: 0.005777\n",
            "Epoch: 136, Loss: 0.013478\n",
            "Epoch: 137, Loss: 0.009434\n",
            "Epoch: 138, Loss: 0.004790\n",
            "Epoch: 139, Loss: 0.028639\n",
            "Epoch: 140, Loss: 0.015011\n",
            "Epoch: 141, Loss: 0.007727\n",
            "Epoch: 142, Loss: 0.012727\n",
            "Epoch: 143, Loss: 0.004017\n",
            "Epoch: 144, Loss: 0.004373\n",
            "Epoch: 145, Loss: 0.017635\n",
            "Epoch: 146, Loss: 0.013671\n",
            "Epoch: 147, Loss: 0.004002\n",
            "Epoch: 148, Loss: 0.034303\n",
            "Epoch: 149, Loss: 0.004575\n",
            "Epoch: 150, Loss: 0.006177\n",
            "Epoch: 151, Loss: 0.015890\n",
            "Epoch: 152, Loss: 0.015179\n",
            "Epoch: 153, Loss: 0.014417\n",
            "Epoch: 154, Loss: 0.006655\n",
            "Epoch: 155, Loss: 0.012737\n",
            "Epoch: 156, Loss: 0.011788\n",
            "Epoch: 157, Loss: 0.009223\n",
            "Epoch: 158, Loss: 0.012633\n",
            "Epoch: 159, Loss: 0.003591\n",
            "Epoch: 160, Loss: 0.008465\n",
            "Epoch: 161, Loss: 0.007356\n",
            "Epoch: 162, Loss: 0.009766\n",
            "Epoch: 163, Loss: 0.013310\n",
            "Epoch: 164, Loss: 0.006266\n",
            "Epoch: 165, Loss: 0.011562\n",
            "Epoch: 166, Loss: 0.012952\n",
            "Epoch: 167, Loss: 0.011708\n",
            "Epoch: 168, Loss: 0.005875\n",
            "Epoch: 169, Loss: 0.117703\n",
            "Epoch: 170, Loss: 0.005814\n",
            "Epoch: 171, Loss: 0.014627\n",
            "Epoch: 172, Loss: 0.005956\n",
            "Epoch: 173, Loss: 0.013054\n",
            "Epoch: 174, Loss: 0.014882\n",
            "Epoch: 175, Loss: 0.002890\n",
            "Epoch: 176, Loss: 0.020172\n",
            "Epoch: 177, Loss: 0.008974\n",
            "Epoch: 178, Loss: 0.012495\n",
            "Epoch: 179, Loss: 0.012869\n",
            "Epoch: 180, Loss: 0.012657\n",
            "Epoch: 181, Loss: 0.003162\n",
            "Epoch: 182, Loss: 0.013693\n",
            "Epoch: 183, Loss: 0.006972\n",
            "Epoch: 184, Loss: 0.009088\n",
            "Epoch: 185, Loss: 0.011540\n",
            "Epoch: 186, Loss: 0.029110\n",
            "Epoch: 187, Loss: 0.003643\n",
            "Epoch: 188, Loss: 0.011313\n",
            "Epoch: 189, Loss: 0.004834\n",
            "Epoch: 190, Loss: 0.005069\n",
            "Epoch: 191, Loss: 0.012123\n",
            "Epoch: 192, Loss: 0.004752\n",
            "Epoch: 193, Loss: 0.014521\n",
            "Epoch: 194, Loss: 0.002701\n",
            "Epoch: 195, Loss: 0.002230\n",
            "Epoch: 196, Loss: 0.008071\n",
            "Epoch: 197, Loss: 0.014820\n",
            "Epoch: 198, Loss: 0.005687\n",
            "Epoch: 199, Loss: 0.004376\n",
            "Elapsed Training Time: 124.81433081626892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZCtEenDNsol",
        "outputId": "e0dfc916-6d68-4a23-eda4-9c27f524aafb"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "print(\"Using %s.\" % device)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda.\n",
            "Accuracy: 0.998650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS6Tor80Nsom",
        "outputId": "0c955283-f141-46a8-f2a7-aec573dd7667"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "print(\"Using %s.\" % device)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda.\n",
            "Accuracy: 0.898750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPu_qyT6ap1Y"
      },
      "source": [
        "**Question 2 Part 2:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6tcdpXUui7b"
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM49xTwJukQt",
        "outputId": "62af724a-61e5-43ee-fdcf-0cfc9cae7459"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch7/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGiYGecvukFx"
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyWIZeEKauJU"
      },
      "source": [
        "label_map = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10 \n",
        "          if label in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jTkZFq0Nsom",
        "outputId": "0f9cafda-70f6-46b1-ea30-c72491a07d5a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "print(\"Training on %s.\" % device)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n",
        "model = Net()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "\n",
        "t = time.time()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "elapsed = time.time() - t\n",
        "print(\"Elapsed Training Time: %s\" % elapsed)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on cuda.\n",
            "Epoch: 0, Loss: 1.944742\n",
            "Epoch: 1, Loss: 1.836574\n",
            "Epoch: 2, Loss: 1.329604\n",
            "Epoch: 3, Loss: 0.990800\n",
            "Epoch: 4, Loss: 1.356710\n",
            "Epoch: 5, Loss: 1.105756\n",
            "Epoch: 6, Loss: 1.176264\n",
            "Epoch: 7, Loss: 1.055281\n",
            "Epoch: 8, Loss: 1.385860\n",
            "Epoch: 9, Loss: 1.275826\n",
            "Epoch: 10, Loss: 1.002669\n",
            "Epoch: 11, Loss: 0.928109\n",
            "Epoch: 12, Loss: 1.099044\n",
            "Epoch: 13, Loss: 1.454239\n",
            "Epoch: 14, Loss: 1.076513\n",
            "Epoch: 15, Loss: 0.754186\n",
            "Epoch: 16, Loss: 0.751196\n",
            "Epoch: 17, Loss: 1.088191\n",
            "Epoch: 18, Loss: 0.885515\n",
            "Epoch: 19, Loss: 1.413347\n",
            "Epoch: 20, Loss: 1.058279\n",
            "Epoch: 21, Loss: 0.850341\n",
            "Epoch: 22, Loss: 1.210542\n",
            "Epoch: 23, Loss: 1.074181\n",
            "Epoch: 24, Loss: 0.527035\n",
            "Epoch: 25, Loss: 0.988931\n",
            "Epoch: 26, Loss: 0.770287\n",
            "Epoch: 27, Loss: 0.906674\n",
            "Epoch: 28, Loss: 0.682707\n",
            "Epoch: 29, Loss: 0.695749\n",
            "Epoch: 30, Loss: 1.280113\n",
            "Epoch: 31, Loss: 1.135671\n",
            "Epoch: 32, Loss: 0.625862\n",
            "Epoch: 33, Loss: 0.741362\n",
            "Epoch: 34, Loss: 0.644328\n",
            "Epoch: 35, Loss: 1.227960\n",
            "Epoch: 36, Loss: 0.940071\n",
            "Epoch: 37, Loss: 0.543236\n",
            "Epoch: 38, Loss: 0.756610\n",
            "Epoch: 39, Loss: 0.699007\n",
            "Epoch: 40, Loss: 0.982059\n",
            "Epoch: 41, Loss: 0.736423\n",
            "Epoch: 42, Loss: 0.948404\n",
            "Epoch: 43, Loss: 1.083974\n",
            "Epoch: 44, Loss: 0.442214\n",
            "Epoch: 45, Loss: 1.392534\n",
            "Epoch: 46, Loss: 1.033102\n",
            "Epoch: 47, Loss: 0.870358\n",
            "Epoch: 48, Loss: 0.820307\n",
            "Epoch: 49, Loss: 0.727670\n",
            "Epoch: 50, Loss: 0.661061\n",
            "Epoch: 51, Loss: 0.573771\n",
            "Epoch: 52, Loss: 1.036876\n",
            "Epoch: 53, Loss: 1.102702\n",
            "Epoch: 54, Loss: 0.862875\n",
            "Epoch: 55, Loss: 0.583028\n",
            "Epoch: 56, Loss: 0.967404\n",
            "Epoch: 57, Loss: 0.574845\n",
            "Epoch: 58, Loss: 0.530082\n",
            "Epoch: 59, Loss: 0.965440\n",
            "Epoch: 60, Loss: 0.955876\n",
            "Epoch: 61, Loss: 1.039903\n",
            "Epoch: 62, Loss: 1.026991\n",
            "Epoch: 63, Loss: 0.768247\n",
            "Epoch: 64, Loss: 0.607791\n",
            "Epoch: 65, Loss: 0.383213\n",
            "Epoch: 66, Loss: 0.833621\n",
            "Epoch: 67, Loss: 0.639656\n",
            "Epoch: 68, Loss: 1.173735\n",
            "Epoch: 69, Loss: 0.383498\n",
            "Epoch: 70, Loss: 0.818309\n",
            "Epoch: 71, Loss: 0.803258\n",
            "Epoch: 72, Loss: 0.523417\n",
            "Epoch: 73, Loss: 0.606597\n",
            "Epoch: 74, Loss: 0.847836\n",
            "Epoch: 75, Loss: 0.834218\n",
            "Epoch: 76, Loss: 0.918676\n",
            "Epoch: 77, Loss: 0.413365\n",
            "Epoch: 78, Loss: 0.640372\n",
            "Epoch: 79, Loss: 0.799882\n",
            "Epoch: 80, Loss: 0.644707\n",
            "Epoch: 81, Loss: 0.912956\n",
            "Epoch: 82, Loss: 1.130740\n",
            "Epoch: 83, Loss: 0.343285\n",
            "Epoch: 84, Loss: 1.415528\n",
            "Epoch: 85, Loss: 0.630405\n",
            "Epoch: 86, Loss: 0.915801\n",
            "Epoch: 87, Loss: 0.502537\n",
            "Epoch: 88, Loss: 1.630988\n",
            "Epoch: 89, Loss: 0.495533\n",
            "Epoch: 90, Loss: 0.521457\n",
            "Epoch: 91, Loss: 0.319975\n",
            "Epoch: 92, Loss: 0.378121\n",
            "Epoch: 93, Loss: 0.940829\n",
            "Epoch: 94, Loss: 0.612462\n",
            "Epoch: 95, Loss: 0.719024\n",
            "Epoch: 96, Loss: 0.853001\n",
            "Epoch: 97, Loss: 0.968860\n",
            "Epoch: 98, Loss: 0.878951\n",
            "Epoch: 99, Loss: 0.245759\n",
            "Epoch: 100, Loss: 0.875792\n",
            "Epoch: 101, Loss: 0.417030\n",
            "Epoch: 102, Loss: 0.977701\n",
            "Epoch: 103, Loss: 0.503286\n",
            "Epoch: 104, Loss: 0.473098\n",
            "Epoch: 105, Loss: 0.348864\n",
            "Epoch: 106, Loss: 0.489179\n",
            "Epoch: 107, Loss: 0.546263\n",
            "Epoch: 108, Loss: 0.197614\n",
            "Epoch: 109, Loss: 0.420085\n",
            "Epoch: 110, Loss: 1.411268\n",
            "Epoch: 111, Loss: 0.401840\n",
            "Epoch: 112, Loss: 1.023716\n",
            "Epoch: 113, Loss: 0.456266\n",
            "Epoch: 114, Loss: 0.396694\n",
            "Epoch: 115, Loss: 0.719284\n",
            "Epoch: 116, Loss: 1.189502\n",
            "Epoch: 117, Loss: 0.660323\n",
            "Epoch: 118, Loss: 0.490263\n",
            "Epoch: 119, Loss: 0.562759\n",
            "Epoch: 120, Loss: 0.985016\n",
            "Epoch: 121, Loss: 0.495557\n",
            "Epoch: 122, Loss: 0.776831\n",
            "Epoch: 123, Loss: 0.193010\n",
            "Epoch: 124, Loss: 0.392861\n",
            "Epoch: 125, Loss: 0.701256\n",
            "Epoch: 126, Loss: 0.778958\n",
            "Epoch: 127, Loss: 0.970705\n",
            "Epoch: 128, Loss: 0.708969\n",
            "Epoch: 129, Loss: 0.415802\n",
            "Epoch: 130, Loss: 0.755556\n",
            "Epoch: 131, Loss: 1.093299\n",
            "Epoch: 132, Loss: 0.317630\n",
            "Epoch: 133, Loss: 0.617185\n",
            "Epoch: 134, Loss: 0.484998\n",
            "Epoch: 135, Loss: 0.606509\n",
            "Epoch: 136, Loss: 0.625758\n",
            "Epoch: 137, Loss: 0.683763\n",
            "Epoch: 138, Loss: 0.374799\n",
            "Epoch: 139, Loss: 0.425212\n",
            "Epoch: 140, Loss: 0.609115\n",
            "Epoch: 141, Loss: 0.679940\n",
            "Epoch: 142, Loss: 0.519194\n",
            "Epoch: 143, Loss: 0.379855\n",
            "Epoch: 144, Loss: 0.586824\n",
            "Epoch: 145, Loss: 0.847390\n",
            "Epoch: 146, Loss: 0.911684\n",
            "Epoch: 147, Loss: 0.367995\n",
            "Epoch: 148, Loss: 0.782767\n",
            "Epoch: 149, Loss: 0.338794\n",
            "Epoch: 150, Loss: 0.797623\n",
            "Epoch: 151, Loss: 0.308271\n",
            "Epoch: 152, Loss: 0.701124\n",
            "Epoch: 153, Loss: 0.348461\n",
            "Epoch: 154, Loss: 0.760687\n",
            "Epoch: 155, Loss: 0.338074\n",
            "Epoch: 156, Loss: 0.562880\n",
            "Epoch: 157, Loss: 0.523019\n",
            "Epoch: 158, Loss: 0.810058\n",
            "Epoch: 159, Loss: 0.445320\n",
            "Epoch: 160, Loss: 0.498207\n",
            "Epoch: 161, Loss: 0.415402\n",
            "Epoch: 162, Loss: 0.268765\n",
            "Epoch: 163, Loss: 0.331672\n",
            "Epoch: 164, Loss: 0.653887\n",
            "Epoch: 165, Loss: 0.587452\n",
            "Epoch: 166, Loss: 0.454475\n",
            "Epoch: 167, Loss: 0.617934\n",
            "Epoch: 168, Loss: 0.578509\n",
            "Epoch: 169, Loss: 0.425783\n",
            "Epoch: 170, Loss: 0.377364\n",
            "Epoch: 171, Loss: 0.348248\n",
            "Epoch: 172, Loss: 0.108061\n",
            "Epoch: 173, Loss: 0.695322\n",
            "Epoch: 174, Loss: 0.621525\n",
            "Epoch: 175, Loss: 0.720491\n",
            "Epoch: 176, Loss: 0.410371\n",
            "Epoch: 177, Loss: 0.523304\n",
            "Epoch: 178, Loss: 0.580081\n",
            "Epoch: 179, Loss: 0.570264\n",
            "Epoch: 180, Loss: 0.571220\n",
            "Epoch: 181, Loss: 0.367712\n",
            "Epoch: 182, Loss: 0.211866\n",
            "Epoch: 183, Loss: 0.492238\n",
            "Epoch: 184, Loss: 0.594549\n",
            "Epoch: 185, Loss: 0.684921\n",
            "Epoch: 186, Loss: 0.463601\n",
            "Epoch: 187, Loss: 0.362783\n",
            "Epoch: 188, Loss: 1.045985\n",
            "Epoch: 189, Loss: 0.346521\n",
            "Epoch: 190, Loss: 0.578782\n",
            "Epoch: 191, Loss: 0.254635\n",
            "Epoch: 192, Loss: 0.570154\n",
            "Epoch: 193, Loss: 0.961039\n",
            "Epoch: 194, Loss: 0.626591\n",
            "Epoch: 195, Loss: 0.521199\n",
            "Epoch: 196, Loss: 0.317555\n",
            "Epoch: 197, Loss: 0.272180\n",
            "Epoch: 198, Loss: 0.717085\n",
            "Epoch: 199, Loss: 0.386734\n",
            "Elapsed Training Time: 313.5781855583191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJmZ2zchbEl4",
        "outputId": "2c2d5aef-83c9-42e7-fab4-1fe024378c0c"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "print(\"Using %s.\" % device)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda.\n",
            "Accuracy: 0.800920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFEHmarGbJGI",
        "outputId": "92aa2496-023b-4a98-a64e-e60dbcdca0a6"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "print(\"Using %s.\" % device)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda.\n",
            "Accuracy: 0.604700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9qePswBbK2j"
      },
      "source": [
        "**Question 2 Part 3:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DBZXXTf6ZyP"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(4 * 4 * 16, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
        "        out = out.view(-1, 4 * 4 * 16)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvW8qiZkVWAx"
      },
      "source": [
        "model = Net()\n",
        "#model(img.unsqueeze(0))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OseJBDGDbn5r",
        "outputId": "dd27f240-c22c-44f5-8b48-5c7ec6636360"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "print(\"Training on %s.\" % device)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(4 * 4 * 16, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
        "        out = out.view(-1, 4 * 4 * 16)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n",
        "model = Net()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "\n",
        "t = time.time()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "elapsed = time.time() - t\n",
        "print(\"Elapsed Training Time: %s\" % elapsed)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on cuda.\n",
            "Epoch: 0, Loss: 2.010870\n",
            "Epoch: 1, Loss: 1.934708\n",
            "Epoch: 2, Loss: 1.846900\n",
            "Epoch: 3, Loss: 1.645098\n",
            "Epoch: 4, Loss: 1.339199\n",
            "Epoch: 5, Loss: 1.252520\n",
            "Epoch: 6, Loss: 1.497247\n",
            "Epoch: 7, Loss: 1.232819\n",
            "Epoch: 8, Loss: 0.822125\n",
            "Epoch: 9, Loss: 1.048250\n",
            "Epoch: 10, Loss: 1.188051\n",
            "Epoch: 11, Loss: 1.014526\n",
            "Epoch: 12, Loss: 0.938415\n",
            "Epoch: 13, Loss: 1.620400\n",
            "Epoch: 14, Loss: 1.552605\n",
            "Epoch: 15, Loss: 1.193309\n",
            "Epoch: 16, Loss: 1.142602\n",
            "Epoch: 17, Loss: 0.809098\n",
            "Epoch: 18, Loss: 1.207442\n",
            "Epoch: 19, Loss: 0.851521\n",
            "Epoch: 20, Loss: 0.893926\n",
            "Epoch: 21, Loss: 1.014975\n",
            "Epoch: 22, Loss: 0.771671\n",
            "Epoch: 23, Loss: 0.727495\n",
            "Epoch: 24, Loss: 0.936012\n",
            "Epoch: 25, Loss: 0.792505\n",
            "Epoch: 26, Loss: 0.719492\n",
            "Epoch: 27, Loss: 1.229041\n",
            "Epoch: 28, Loss: 0.919473\n",
            "Epoch: 29, Loss: 0.582355\n",
            "Epoch: 30, Loss: 0.490523\n",
            "Epoch: 31, Loss: 0.653714\n",
            "Epoch: 32, Loss: 0.923506\n",
            "Epoch: 33, Loss: 0.608235\n",
            "Epoch: 34, Loss: 1.017840\n",
            "Epoch: 35, Loss: 0.737337\n",
            "Epoch: 36, Loss: 0.845214\n",
            "Epoch: 37, Loss: 0.634501\n",
            "Epoch: 38, Loss: 0.822567\n",
            "Epoch: 39, Loss: 0.555087\n",
            "Epoch: 40, Loss: 0.761780\n",
            "Epoch: 41, Loss: 0.535715\n",
            "Epoch: 42, Loss: 0.681177\n",
            "Epoch: 43, Loss: 0.958396\n",
            "Epoch: 44, Loss: 0.600701\n",
            "Epoch: 45, Loss: 0.803818\n",
            "Epoch: 46, Loss: 0.656356\n",
            "Epoch: 47, Loss: 0.552580\n",
            "Epoch: 48, Loss: 0.731860\n",
            "Epoch: 49, Loss: 1.026722\n",
            "Epoch: 50, Loss: 0.801950\n",
            "Epoch: 51, Loss: 0.632829\n",
            "Epoch: 52, Loss: 0.780071\n",
            "Epoch: 53, Loss: 0.946082\n",
            "Epoch: 54, Loss: 0.746402\n",
            "Epoch: 55, Loss: 0.537847\n",
            "Epoch: 56, Loss: 0.753041\n",
            "Epoch: 57, Loss: 0.948018\n",
            "Epoch: 58, Loss: 0.862532\n",
            "Epoch: 59, Loss: 0.814315\n",
            "Epoch: 60, Loss: 0.464233\n",
            "Epoch: 61, Loss: 0.805382\n",
            "Epoch: 62, Loss: 0.732057\n",
            "Epoch: 63, Loss: 0.772941\n",
            "Epoch: 64, Loss: 0.436935\n",
            "Epoch: 65, Loss: 0.472807\n",
            "Epoch: 66, Loss: 0.628891\n",
            "Epoch: 67, Loss: 1.482643\n",
            "Epoch: 68, Loss: 0.360465\n",
            "Epoch: 69, Loss: 0.483484\n",
            "Epoch: 70, Loss: 0.572615\n",
            "Epoch: 71, Loss: 0.253963\n",
            "Epoch: 72, Loss: 0.357060\n",
            "Epoch: 73, Loss: 0.571730\n",
            "Epoch: 74, Loss: 0.673127\n",
            "Epoch: 75, Loss: 0.509844\n",
            "Epoch: 76, Loss: 1.058722\n",
            "Epoch: 77, Loss: 0.758592\n",
            "Epoch: 78, Loss: 0.291345\n",
            "Epoch: 79, Loss: 0.684089\n",
            "Epoch: 80, Loss: 0.708772\n",
            "Epoch: 81, Loss: 0.621676\n",
            "Epoch: 82, Loss: 0.866939\n",
            "Epoch: 83, Loss: 0.729674\n",
            "Epoch: 84, Loss: 0.830737\n",
            "Epoch: 85, Loss: 0.525264\n",
            "Epoch: 86, Loss: 0.790782\n",
            "Epoch: 87, Loss: 0.694915\n",
            "Epoch: 88, Loss: 0.283484\n",
            "Epoch: 89, Loss: 0.373942\n",
            "Epoch: 90, Loss: 0.385749\n",
            "Epoch: 91, Loss: 0.510025\n",
            "Epoch: 92, Loss: 0.527840\n",
            "Epoch: 93, Loss: 0.764393\n",
            "Epoch: 94, Loss: 0.590487\n",
            "Epoch: 95, Loss: 0.758259\n",
            "Epoch: 96, Loss: 0.214777\n",
            "Epoch: 97, Loss: 1.277722\n",
            "Epoch: 98, Loss: 0.848282\n",
            "Epoch: 99, Loss: 0.607791\n",
            "Epoch: 100, Loss: 0.400239\n",
            "Epoch: 101, Loss: 0.906416\n",
            "Epoch: 102, Loss: 0.470946\n",
            "Epoch: 103, Loss: 0.298272\n",
            "Epoch: 104, Loss: 0.744210\n",
            "Epoch: 105, Loss: 0.493594\n",
            "Epoch: 106, Loss: 0.673977\n",
            "Epoch: 107, Loss: 0.582709\n",
            "Epoch: 108, Loss: 0.449817\n",
            "Epoch: 109, Loss: 0.527494\n",
            "Epoch: 110, Loss: 0.616060\n",
            "Epoch: 111, Loss: 0.559802\n",
            "Epoch: 112, Loss: 0.409117\n",
            "Epoch: 113, Loss: 0.647743\n",
            "Epoch: 114, Loss: 0.482479\n",
            "Epoch: 115, Loss: 0.536033\n",
            "Epoch: 116, Loss: 0.466342\n",
            "Epoch: 117, Loss: 0.875248\n",
            "Epoch: 118, Loss: 0.547622\n",
            "Epoch: 119, Loss: 0.361923\n",
            "Epoch: 120, Loss: 0.211891\n",
            "Epoch: 121, Loss: 0.458173\n",
            "Epoch: 122, Loss: 0.337360\n",
            "Epoch: 123, Loss: 0.327912\n",
            "Epoch: 124, Loss: 0.226756\n",
            "Epoch: 125, Loss: 0.394801\n",
            "Epoch: 126, Loss: 0.331710\n",
            "Epoch: 127, Loss: 0.599831\n",
            "Epoch: 128, Loss: 0.573866\n",
            "Epoch: 129, Loss: 0.725080\n",
            "Epoch: 130, Loss: 0.323863\n",
            "Epoch: 131, Loss: 0.463602\n",
            "Epoch: 132, Loss: 0.848274\n",
            "Epoch: 133, Loss: 0.569581\n",
            "Epoch: 134, Loss: 0.165925\n",
            "Epoch: 135, Loss: 0.414977\n",
            "Epoch: 136, Loss: 0.900080\n",
            "Epoch: 137, Loss: 0.491250\n",
            "Epoch: 138, Loss: 0.729335\n",
            "Epoch: 139, Loss: 0.481044\n",
            "Epoch: 140, Loss: 0.410415\n",
            "Epoch: 141, Loss: 0.381568\n",
            "Epoch: 142, Loss: 0.269773\n",
            "Epoch: 143, Loss: 0.223793\n",
            "Epoch: 144, Loss: 0.980063\n",
            "Epoch: 145, Loss: 0.531239\n",
            "Epoch: 146, Loss: 1.155688\n",
            "Epoch: 147, Loss: 0.584966\n",
            "Epoch: 148, Loss: 0.324738\n",
            "Epoch: 149, Loss: 0.343095\n",
            "Epoch: 150, Loss: 0.358503\n",
            "Epoch: 151, Loss: 0.465843\n",
            "Epoch: 152, Loss: 0.678424\n",
            "Epoch: 153, Loss: 0.569766\n",
            "Epoch: 154, Loss: 0.829717\n",
            "Epoch: 155, Loss: 0.106867\n",
            "Epoch: 156, Loss: 0.466233\n",
            "Epoch: 157, Loss: 0.458604\n",
            "Epoch: 158, Loss: 0.584429\n",
            "Epoch: 159, Loss: 0.441747\n",
            "Epoch: 160, Loss: 0.160189\n",
            "Epoch: 161, Loss: 0.417309\n",
            "Epoch: 162, Loss: 0.552565\n",
            "Epoch: 163, Loss: 0.288176\n",
            "Epoch: 164, Loss: 1.112131\n",
            "Epoch: 165, Loss: 0.705739\n",
            "Epoch: 166, Loss: 0.210947\n",
            "Epoch: 167, Loss: 0.511901\n",
            "Epoch: 168, Loss: 0.368984\n",
            "Epoch: 169, Loss: 0.473663\n",
            "Epoch: 170, Loss: 0.164578\n",
            "Epoch: 171, Loss: 0.782643\n",
            "Epoch: 172, Loss: 0.939861\n",
            "Epoch: 173, Loss: 0.629099\n",
            "Epoch: 174, Loss: 0.416530\n",
            "Epoch: 175, Loss: 0.352656\n",
            "Epoch: 176, Loss: 0.873964\n",
            "Epoch: 177, Loss: 0.510283\n",
            "Epoch: 178, Loss: 0.691948\n",
            "Epoch: 179, Loss: 0.274572\n",
            "Epoch: 180, Loss: 0.577278\n",
            "Epoch: 181, Loss: 0.540175\n",
            "Epoch: 182, Loss: 0.265028\n",
            "Epoch: 183, Loss: 0.740296\n",
            "Epoch: 184, Loss: 0.455421\n",
            "Epoch: 185, Loss: 0.616452\n",
            "Epoch: 186, Loss: 0.422301\n",
            "Epoch: 187, Loss: 0.771101\n",
            "Epoch: 188, Loss: 0.473151\n",
            "Epoch: 189, Loss: 0.578326\n",
            "Epoch: 190, Loss: 0.321718\n",
            "Epoch: 191, Loss: 0.908848\n",
            "Epoch: 192, Loss: 0.314449\n",
            "Epoch: 193, Loss: 0.705995\n",
            "Epoch: 194, Loss: 0.237723\n",
            "Epoch: 195, Loss: 0.632907\n",
            "Epoch: 196, Loss: 0.245984\n",
            "Epoch: 197, Loss: 0.461830\n",
            "Epoch: 198, Loss: 0.577061\n",
            "Epoch: 199, Loss: 0.606336\n",
            "Elapsed Training Time: 357.300656080246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlEYSdZ4Nsom",
        "outputId": "4aed6d8d-75e2-4712-9bad-3ea2f4766433"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "print(\"Using %s.\" % device)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda.\n",
            "Accuracy: 0.765400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjqJXTYe8Taj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14833121-173a-4ffd-bc41-2b37f620f1e9"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "print(\"Using %s.\" % device)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda.\n",
            "Accuracy: 0.659400\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}